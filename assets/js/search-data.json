{
  
    
        "post0": {
            "title": "Pocodes",
            "content": ". title: “POCODES: POssible COllision DEtection System” description: “Part [2/3] of my Road to Masters story” layout: post toc: true branch: master badges: false image: images/ipynb/colision_predictions1.png comments: false author: Giaco Stantino categories: [computer vision, machine learning] hide: false search_exclude: true permalink: /blog/pocodes . . Intro . “Contrary to traditional beliefs, high-level reasoning requires low computing power, but low-level perception and abilities motor skills require enormous computing power.”~Moravec paradox . Indeed, computers have learned chess against people earlier than they have learned to recognize items in photos or in the vicinity of the car. The following post is based on the project and report I done for my univeristy project. I had to design aglorithm and model that would spot the possibile collisions in the frame of the video. Fun fact: this is the project that convinced me that ML is what I’d like consider for my master’s thesis and maybe for coming years. . Prelude . The growing number of vehicles on the road has visible consequences, including congested streets in densely populated cities and an increasing number of car accidents from year to year. A 2019 World Health Organization (WHO) report shows that 1.25 million people die in road accidents each year and millions more are injured, with nearly 49% of pedestrians and cyclists. Moreover, it is estimated that road accidents will be the fifth leading cause of death in the world by 2030 if preventive measures are not taken. . At the same time, there is an increase in the use of drones and the development of related industries. By 2025, the size of the drone services market is expected to grow to $ 63.6 billion. In addition, in 2021, deliveries of consumer drones are expected to reach 29 million. At this point, attention should be paid to the presence of vision systems in most models available on the market. . The use of artificial intelligence and computer vision for the image obtained from the drone’s camera to detect potential collisions may significantly accelerate the process of providing information about the accident. The time it takes for victims to wait for help could be shortened. Such a system should be fully automatic and operate with high reliability. . Object Detection . Object detection is the task of detecting instances of objects of a certain class within an image. The state-of-the-art methods can be categorized into two main types: one-stage methods and two stage-methods. One-stage methods prioritize inference speed, and example models include YOLO and SSD. Two-stage methods prioritize detection accuracy, and example models include Faster R-CNN and Mask R-CNN. . Algorithms produce a list of object categories present in the image along with an axis-aligned bounding box indicating the position and scale of every instance of each object category. In fact, there are two types of boxes that you should know: . The bounding box is used to describe the spatial location of an object, as shown in the above photo | The ground-truth box is used on training data to mark the object | . Model used - SSD . In 2015, Wei Liu et al. published the work “SSD: Single Shot MultiBox Detector”. This algorithm uses boxes of different sizes to recognize objects of different types in any image. Thanks to the use of this technique, it is possible to recognize large and small objects in the same image. . SSD has two components: a backbone model and SSD head. Backbone model usually is a pre-trained image classification network as a feature extractor. This is typically a network like ResNet trained on ImageNet from which the final fully connected classification layer has been removed. We are thus left with a deep neural network that is able to extract semantic meaning from the input image while preserving the spatial structure of the image albeit at a lower resolution. The SSD head is just one or more convolutional layers added to this backbone and the outputs are interpreted as the bounding boxes and classes of objects in the spatial location of the final layers activations. In the figure below, the first few layers (white boxes) are the backbone, the last few layers (blue boxes) represent the SSD head. . The algorithm creates a mesh and checks for each location whether the object is potentially there. Then it selects the correct proportions of the default boundaries for the searched object. In the SSD model, this stage is accomplished by the standard VGG-16 convolutional network model. . The figure above from the left shows GT (ground-truth) boxes where two animal objects (dog and cat) were found, the center shows an 8 x 8 map and finding a smaller element, and the right shows the location coordinates (loc) and values ​​representing the trust of the found object on the basis of the compared features (conf). . Collision detection algorithm . The SSD model is used to predict bounding boxes of objects in the frame. The risk of a potential accident is detected by checking the IoU (Intersection over Union) factor for each pair of objects visible in the frame. This concept is sufficient for frames with a limited number of objects, but might not work in places with extremely high density of objects, such as passersby and cars in Times Square, New York . The IoU factor is used to determine the degree to which two objects overlap, namely their predicted boundaries. It is calculated by dividing the intersection of the surfaces bounded by the boundaries by the sum of both surfaces, as shown in the following illustration. . Results . The SSD300 neural network model was used to detectthe objects. The database was recordings from Stanford University with annotations already prepared. An example frame below. . The analysis was carried out for single frames of films available in the above-mentioned database. 624 frames were selected pseudo-randomly for the training set and 132 for the validation set. Such a selection was aimed at diversifying the set, because the two consecutive frames of a film with a frequency of 30 fps do not differ much from each other. . Predictions . Trained model allows to recognize objects of various classes: Biker, Skateboarder and Car. Examples of frames with prediction plotted from two locations are presented below. . AP (Average Precision) was used to assess the quality, which is an indicator showing the effectiveness of predictions in percent, i.e. the ratio of correct predictions to all predictions made. The average precision value for both scenes was 73.51%, which is not a sufficient enough for the stable and reliable collision detection system. . Collisions . The risk of a potential accident was detected by checking the IoU factor for each pair of objects predicted in the frame. For the purposes of the project, it was decided that the IoU factor must be greater than 0.3 to detect collision. . We can see possible collisions in the picture above. The next step in improving considered detection system could be to analyze whether the drop in speed is large enough between suspected objects to confirm the collision. . Summary . The project discusses a collision detection system based on computer vision solutions using artificial neural networks from recent years. A system was obtained that recognizes objects of various classes of road users and checks the locations of potential collisions. The average effectiveness of the recognition of objects was at the level of 75.51% which is not a sufficient value. Finally, a solution for detecting collisions of detected objects using the IoU coefficient was proposed. . This sums up the blog post. As you can see, the project was not an unbelievable success… in fact it was not successful at all. Well, at least when it comes to the results. Despite that, it managed to ignite my curiosity. I can’t wait to post the last part of this saga, which is my master’s thesis: video object segmentation. . P.S. Sorry for that clickbait title, POCODES :laugh: .",
            "url": "https://giacostantino.com/pocodes/",
            "relUrl": "/pocodes/",
            "date": " • Mar 14, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Object Recognition",
            "content": ". title: “Intro to object recognition and convnets” description: “Part [1/3] of my Road to Masters story” layout: post toc: true branch: master badges: false image: images/ipynb/rtm_object_recognition.png comments: false author: Giaco Stantino categories: [computer vision, machine learning] hide: false search_exclude: true permalink: /blog/object-recognition . . Intro . Object recognition is a computer vision technique for identifying objects in images or videos. Object recognition is a key technology behind driverless cars, enabling them to recognize a stop sign or to distinguish a pedestrian from a lamppost. It is also useful in a variety of applications such as disease identification in bioimaging, industrial inspection, and robotic vision. . This blog post is a result of my deep interest in neural networks. It is also the first part of three epsiode series, which sums up my experiences with computer vision until my master’s thesis, which is the final part. All of the posts are discussing the core concepts and ideas behind the projects. However for this part I uploaded the notebook to my github repo. . Neural Networks . This is one of the prerequists for this blogpost. It would be best if you understand the concept - here is a good article. tldr: Neural Networks are algorithms using an artificial neurons. They compute output value based on inputs (x1, x2, x3) - to do that they learn input weights and then pass it to activation function. . For indepth info check: Michael Nielsen’s internet book . Deep Neural Networks . Neural Network that use multiple layers of artifical neurons, are called deep neural networks. . Above we can see the most basic concept of MLP (multi layer perceptron). Such models are characterized by a hierarchical structure, i.e. transformations take place on many layers, thanks to which you can take advantage of the possibility of returning. At each layer created is a data abstraction representation, another one for a different process for equated neural networks that are inherited. . The use of deep neural networks for image analysis is a promising idea. We assign each pixel in the grayscale image a numeric value, such as 0 for black to 1 for white. For a 16px x 16px image, there are 256 values ​​that are passed as input values. In the case of the color scale, the colors of the image are broken down into three RGB channels, which gives 3x256 values ​​of the input data. However, the transmission of information from pixels directly to the MLP neurons results in the appearance of the following problem . The figure above shows the frame of the detected cat’s head. The deep neural network in the learning process will only acquire the face recognition insights at this image location - the corresponding weights will be modified - as shown on the right. In other words, the network will learn to recognize a cat in specific locations. In order to solve this problem, the architecture of convolutional networks was proposed. . ConvNets . These networks get their name from the mathematical convolution operation. The convolutional neural network consists of an input layer, convolutional layers and an output layer. On CNN, hidden layers perform convolutions. . As shown above, a convolutional layer is one that takes the dot product of the kernel with the input matrix. The convolution operation generates a feature map, which in turn affects the input for the next layer. This is followed by other layers such as pool layers, or fully linked layers. . The concept of convolutional layers is based on simple assumptions: . nearby pixels are more important than far apart pixels, | objects are made up of smaller parts. | The influence of the surrounding pixels is analyzed using filters, usually 3x3 or 5x5. Such a filter moves across the entire image, the step of this shift is called a stride. Above figure shows a simple convolutional operation of applying a filter to the input pixel. For each point in the image, an output value is computed using convolution operations. The matrix of those outputs is called feature map. . The pooling layers then extract the most important information from the feature maps, get rid of the noise, and thus condense the information into smaller maps. Finally, the feature map neurons are flattened into a vector form and fully connected to the next layer that generates predictions. . Although Convolution Networks produce acceptable outputs there was one more evolution to be made (well, a few more in fact, but we will consider today this one). . ResNets . One of the problems of the neural network is that with each successive layer it becomes more difficult to propagate information from the early layers and the accuracy of the network results decreases - this is known as the degradation problem. As a solution to this problem, residual blocks, which are a modification of convolutional blocks, have been proposed . Let F (x) be a function learned by the layers. Consider the output y = F (x) + x, for a block omitting connections. Here the term + x means a combination of the so-called “residual”. For y = F (x) + x, where the +x component carries the original value, the block only needs to learn the value changes, i.e. the residual Δx. In other words, this approach changes the ‘intuition’ of training from simply recognizing features to learning the differences between them. Hence the name “Residual Learning”. . Object Recognition . Object recognition is a computer vision technique used to identify objects in images or videos. Object recognition is a key result of deep learning and machine learning algorithms. When people look at a photo or watch a video, we can easily see people, objects, scenes, and visual details. The goal is to teach the computer to do what naturally comes to a person: gain a level of understanding of what the picture contains. . In the project in my repository I trained a resnet model to classify animals base on their picture. Here are some sample results. . Model’s performance in evaluated based on it’s accuracy score. In perfect world it would be so easy to assess if our experiments end with a satisifing result. Unfortunately, we don’t live on ideal planet. One of the problems of the neural networks that they might overfit during the training. In other words, they will learn by heart without understandind the essensce of the data. If put to the tests, they will score best on pictures their learned with, but perform miserably with data they see first time. . Overfitting . To prevent model from learing by heart (overfitting) we need to spot it happening first. The very basic tool for this is learning curve. There are ploted results of the model on training data and test (unseen) data by number of epochs (number of times model seen whole dataset). . Above I plotted the learning curve for my animals recognition project. It turns out that model starts overfiting after epoch 14 - when validation and traning curve drift apart and the accuracy graph stops growing. . To prevent this from happening earlier, my model uses a few regularization techniques: . scheduled learning rate | gradient clipping | weight decay | . Note: There is a lot of diffrent techniques. I chose the ones that, in my opinion, suited the project best. . Summary . The neural network model is a powerfull tool and is best suited for tasks where traditional machine learning algorithms underperform, such as computer vision and speech recognition. In the post we discussed the core ideas behind the object recognition, yet there is a lot lef unsaid: neuron activation function, loss function, optimization method… Some of them I am going to discuss in upcoming post considering object detction for colision signaling. Stay tuned. .",
            "url": "https://giacostantino.com/object-recognition/",
            "relUrl": "/object-recognition/",
            "date": " • Mar 7, 2022"
        }
        
    
  
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": ". My name is Jakub Konstanty and I&#39;m self-taught machine learning engineer. During my time at University I was first fascinated with CAD and 3D modeling. There was always something to tune, fix and enhance. The process of designing was very appealing to me. Then, during my masters I discovered the world of neural networks and computer vision. It switched my focus from irl to ml design. . My blog posts are mainly geared towards my experiences and development with Machine Learning and Computer Vision as Video Object Segmentation was my thesis. I will also explore some areas of Data Science as it and ml are complementary fields. Most of my post will have tutorial or explanatory character. However, I might post some photos from my climbing trips at some point in the future. . Reach me out via email: giastantino@gmail.com. You can find me on GitHub . . Passionate about... . Climbing | Hiking | Books | Coding | CAD Design &amp; Modelling | . . Thinking about... . Data Science | ML Ops | Computer Vision | Stoicism | fast.ai &amp; PyTorch | . . 🔭 Software Tools . 🛠 Programming . 🛠 Machine Learning .",
          "url": "https://giacostantino.com/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  
      ,"page2": {
          "title": "Arts",
          "content": "Music, poetry etc. . Along with my passion for computer vision I do spend most of my free time composing music. . I play the keyboards for Keyband. . “Melancholy” is an original composition I composed using FL Studio . Keyband did have the wonderful opportunity to perform alongside Alphonse Joseph . Some of our performances with him… . I also do spent some time writing snippets of poems: .",
          "url": "https://giacostantino.com/arts/",
          "relUrl": "/arts/",
          "date": ""
      }
      
  

  
      ,"page3": {
          "title": "Blog",
          "content": "",
          "url": "https://giacostantino.com/blog/",
          "relUrl": "/blog/",
          "date": ""
      }
      
  

  

  
      ,"page5": {
          "title": "My Favourites",
          "content": ". Music Blue Neighbourhood Troye Sivan Pop · 2015 . Kamikaze Eminem Hip-Hop/Rap · 2018 . No.6 Collaborations Project Ed Sheeran Pop · 2019 . The 20/20 Experience Justin Timberlake Pop · 2019 . BURDEN BONES Hip-Hop/Rap · 2021 . All Eyez On Me 2Pac Hip-Hop/Rap · 1996 . Dopamine BØRNS Alternative · 2015 . Live at the Royal Albert Hall Bring Me The Horizon Rock · 2020 . Tha Carter IV Lil Wayne Hip-Hop/Rap · 2020 . The Infamous Mobb Deep Hip-Hop/Rap · 1995 . Truth Is a Beautiful Thing London Grammar Alternative · 2017 . 88GLAM2.5 88GLAM Hip-Hop/Rap · 2019 . Beauty Behind the Madness The Weeknd R&amp;B/Soul · 2015 . Stop Staring at the Shadows $uicideboy$ Hip-Hop/Rap · 2020 . Blurryface twenty one pilots Rock · 2015 . 1000 Forms Of Fear Sia Pop · 2014 . . Books . Movies . Podcasts Reflecting History Reflecting History . Making Sense with Sam Harris Sam Harris . The Jordan B. Peterson Podcast Dr. Jordan B. Peterson . Epsilon Theory Podcast Ben Hunt . Naval Naval Ravikant . . Articles Professor Scott Galloway - The Great Grift . Paul Ford - What Is Code? If You Don&#39;t Know, You Need to Read This . The Last Psychiatrist - Who&#39;s Afraid Of Lil Wayne? . Scott Galloway - The Algebra of Wealth . NASA - The Tyranny of the Rocket Equation . Ken Liu - Paper Menagerie . Hunter S. Thompson - Letter on Finding Your Purpose and Living a Meaningful Life . Hans Christian Andersen - Kejserens Nye Klæder (The Emperor&#39;s New Clothes) . David Foster Wallace - This is Water . Ted Chiang - The Merchant and the Alchemist&#39;s Gate . Paul Graham - What You Can&#39;t Say . . Quotes “Once is happenstance. Twice is coincidence. Three times is enemy action.” . ― Ian Fleming . “Tradition is a set of solutions for which we have forgotten the problems” . ― Donald Kingsbury . “People fear death even more than pain. It&#39;s strange that they fear death. Life hurts a lot more than death. At the point of death, the pain is over. Yeah, I guess it is a friend.” . ― Jim Morrison . “There is something profoundly cynical, my friends, in the notion of paradise after death. The lure is evasion. The promise is excusative. One need not accept responsibility for the world as it is, and by extension, one need do nothing about it. To strive for change, for true goodness in this mortal world, one must acknowledge and accept, within one&#39;s own soul, that this mortal reality has purpose in itself, that its greatest value is not for us, but for our children and their children. To view life as but a quick passage along a foul, tortured path - made foul and tortured by our own indifference - is to excuse all manner of misery and depravity, and to exact cruel punishment upon the innocent lives to come.I defy this notion of paradise beyond the gates of bone. If the soul truly survives the passage, then it behooves us - each of us, my friends - to nurture a faith in similitude: what awaits us is a reflection of what we leave behind, and in the squandering of our mortal existence, we surrender the opportunity to learn the ways of goodness, the practice of sympathy, empathy, compassion and healing - all passed by in our rush to arrive at a place of glory and beauty, a place we did not earn, and most certainly do not deserve.”The Apocryphal Teachings of Tanno Spiritwalker Kimloc; The Decade in Ehrlitan . ― Steven Erikson, The Bonehunters . “If you&#39;re harmless, you&#39;re not virtuous. You&#39;re just harmless. You&#39;re like a rabbit. A rabbit isn&#39;t virtuous. It can&#39;t do anything but get eaten.If you&#39;re a monster and you don&#39;t act monstrous, then you&#39;re virtuous. ” . ― Jordan B. Peterson . “Pity those who want the perfect life! Break me, tear me apart, let me be beaten and altered by life, let my life be touched and touch in return for I will be Human, for there is no reason on earth to be scared of yourself.Perfect is boring... let it be written in the sky, painted on buildings, read with your eyes, transcribed on your soul.” . ― Unknown . “Just because fate has chosen something for you instead of you choosing it for yourself doesn’t mean it has to be bad. Even if it’s something you are sure you would never have chosen in a hundred years.” . ― Robert Jordan, The Dragon Reborn . “The Wheel of Time turns, and ages come and pass, leaving memories that become legend. Legend fades to myth, and even myth is long forgotten when the Age that gave it birth comes again. In one Age, called the Third Age by some, an Age yet to come, an Age long past, a wind rose in the Mountains of Mist. The wind was not the beginning. There are neither beginnings nor endings to the turning of the Wheel of time. But it was a beginning.” . ― Robert Jordan, The Eye of the World . “A young wolfhound must meet his first wolf someday, but if the wolf sees him as a puppy, if he acts the puppy, the wolf will surely kill him. The wolfhound must be a wolfhound in the wolf&#39;s eyes even more than in his own, if he is to survive.” . ― Robert Jordan, The Great Hunt . “There are no atheists in foxholes. In the end, everyone prays.” . ― Unknown .",
          "url": "https://giacostantino.com/favourites/",
          "relUrl": "/favourites/",
          "date": ""
      }
      
  

  

  
  

  
      ,"page8": {
          "title": "Poetry",
          "content": "",
          "url": "https://giacostantino.com/poetry/",
          "relUrl": "/poetry/",
          "date": ""
      }
      
  

  
      ,"page9": {
          "title": "Resume",
          "content": "Deep Wilson Aricatt . deep.16wilson@gmail.com | +91 8767102424 GitHub | LinkedIn | StackOverflow . About myself . Passionate computer vision developer with proven experience of creating and deploying models related to object detection, instance segmentation, face recognition/detection from scratch along with active contribution to open-source projects | . Work Experience . Siemens . Sr. Machine learning Engineer (May 2021 - Present) . Currently working on building object detection pipelines for various use cases | Worked on 3D object detection algorithms | Worked on image segmentation problems | Implemented anomaly detection algorithms for time series data | . Orbo.ai . Computer Vision Engineer (October 2019 - May 2021) . Lead the Face Recognition project for Mumbai Metro (MMRDA) Literature survey and training models from scratch with large-scale data along with OpenVINO optimization and hardware setup. Data augmentation to tackle racial bias (specific to Indian faces) and low lighting without sacrificing LFW accuracy (99.3%) | Face detection model on the lines of LFFD (A Light and Fast Face Detector for Edge Devices) for real-time crowd monitoring. | Packaged deep learning models (SR, face mask detection, social distance monitoring etc.) into production level C++ SDKs for clients oriented towards deployment on edge devices like routers (Client - Cisco) | Created Super Resolution models using Residual Dense Block architecture for entertainment industry and mobile phones (lightweight models by pruning and quantization) | Created benchmarking tools to assess model performance in terms of VMAF, PSNR, SSIM etc. for super resolution applications | . Yrals Digital Pvt. Ltd. . Developer Python | Machine Learning (March 2017 - October 2019) . Developed TV Feed Analyzer an automated commercial extraction and story segregation platform based on broadcast video (news feed) for Times Now and Zee News(Zee Hindi and Wion) by deploying: Machine learning techniques (HOG+LSTM, CNNs, PCA, linear regression) for anchor detection, face recognition, scrolling text band detection etc. | Traditional CV methods (shot detection, Hough Line transform) for scene classification, footage box detection etc. | Audio analysis (MFCC based Voice Activity Detection) | | Built scalable back-end from scratch for “TV Feed Analyzer” using AWS Lambda, EC2 and Mongo DB (system design, DB architecture, cron automation etc.) | Deployed end to end machine learning pipelines on AWS | Found solutions to problems in the video processing domain to optimize workflow and avoid bottle necks related to speed as well as compute costs on AWS (multi-processing in serverless environment) | Joined as junior Python Developer to produce maintainable and well documented code for analytical and research-oriented problems related to computer vision, audio and video processing | . MATLAB Helper . MATLAB Developer (July 2016 - August 2016) . Advanced MATLAB Project implementation dealing with: . Image Processing | Machine Readable Zone Detection | Optical Character Recognition and other important topics related to physics | Writing tutorials and code (in MATLAB) spanning concepts such as Monte Carlo simulation, Harris corner detection, Radon transform, etc. | . Education . Don Bosco Institute of Technology, Mumbai Bachelor’s degree (Electronics and Telecommunications Engineering) 2012 - 2016 . Certifications . State Estimation and Localization for Self-Driving Cars | Practical Machine Learning with Tensorflow 2.0 | Machine Learning for Engineering and Science Applications (NPTEL) | Programming, Data structures and algorithms using Python (NPTEL) | Foundations of Wavelets and Multirate Digital Signal Processing (NPTEL) | Sparse Optimization for Signals &amp; Systems (Indian Institute of Technology, Madras) | . Technical Skills . Industry Knowledge: Computer Vision / Machine Learning / Deep Learning o OpenVINO optimization (C++ &amp; Python) o AWS (AWSCLI, S3, Lambda, EC2, CloudFront) o Data Structures and Algorithms o Basic front-end skills o Github o 3D Computer Vision o Lidar data processing . Programming: Python (Proficient) o C/C++ (Intermediate) o CUDA programming o JavaScript o PHP o MATLAB o VHDL . Machine learning frameworks: PyTorch (torchvision, torchaudio) o Keras API (Tensorflow backend) o Tensorflow 2.0 o Scikit Learn . Interpersonal Skills: Public Speaking o Pitching products (sales pitch) . Key Projects . Face recognition using Arcface and Face detection using LFFD | Image Classifier for fine grained classification and imbalanced dataset | Voice Activity Detection based on MFCC/spectrogram classification | Automated audio levelling for byte footages (NAT sound) | Trending article suggestion based on K-means clustering | Intelligent seam carving &amp; Background removal | Blurred text detection using LSTM | Object detection pipeline (SSD/Faster-RCNN) | U-Net text detection | . Extracurriculars and Achievements . Speaker at DevOps India Summit-21 Topic-“Chaos engineering for Artificial Intelligence using MLOps approach” | Keyboardist, song writer @ Keyband - Official band of Kalyan Eparchy Youth (Performed with artists including Alphonse Joseph and Rexband) | Trinity Guildhall certified Keyboardist | Served as Choirmaster for St. Joseph’s Church, MC Road (2018-2022) | Invited by Don Bosco Institute of Technology, Mumbai to conduct a session on “Machine Learning - Current Trends &amp; Avenues” | Secured 1st prize in “Instrumental Event” at CREXTAL 2014 | Led the St. Joseph’s Church, MC Road Church Choir to victory at Fr. Sunny Memorial Church Choir Competition in the year 2018 | Secured 2nd place in “Debate” at TALENTIA 2015 | Secured 5th place in “One Minute to Fame (Keyboards)” at TALENTIA 2015 | Secured “ELITE” status in NPTEL certification course “Practical Machine Learning with Tensorflow 2.0” | .",
          "url": "https://giacostantino.com/resume/",
          "relUrl": "/resume/",
          "date": ""
      }
      
  

  
  

  

  
  

  

  
  

  
  

  
  

  
  

  
  

}